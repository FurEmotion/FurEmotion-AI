# FurEmotion-AI
## 간단 소개
이 프로그램에서 맡고 있는 이 FurEmotion-Ai는<br n>
동물의 울음소리를 분석하고 감정을 알아내는 모델을 만들기 위한 레포지토리입니다.

## 목표
반려동물과 반려인과의 더 나은 소통을 위해 울음 분석 모델을 만들려고 한다.

## 진행 방향
주기적으로 프로토타입을 선보이면서 진행하는 애자일 개발 방식을 이용함.<br n>
파이토치나 텐서플로우를 사용할 예정.<br n>


## 일정

- 1주차: 프로젝트 준비 및 요구사항 정의: 고객 및 반려동물 보호자의 요구사항을 바탕으로 주요 기능 및 성능 목표 설정.
- 2~3주차: 반려동물 울음소리 데이터 수집(공개 데이터셋 활용) 및 전처리. 데이터 정제 및 필터링 작업 수행.
- 4~5주차: MobileNet 기반 on-device AI 모델 개발 및 초기 테스트(on-device 구현 유효성 판단). 울음소리 감지를 위한 실시간 분류 시스템 구축.
- 6~7주차: 푸리에 변환 및 멜 필터뱅크 적용하여 울음소리 데이터를 3D 이미지로 변환. Computer Vision 기술(CNN 또는 ViT) 적용 및 훈련.
- 8주차: Flutter 기반 모바일 애플리케이션 UI/UX 설계 및 프로토타입 개발. 음성 데이터 실시간 감지 기능 통합.
- 1차 중간평가 목표: 울음 감지 모델을 어플리케이션에 탑재 및 시연.
- 9~10주차: FastAPI 기반 백엔드 시스템 개발. TensorFlow 또는 PyTorch와 연동해 AI 모델과 실시간 데이터 처리 연동.
- 11주차: 모바일 기기 성능 최적화 작업(발열, 지연 문제 해결). on-device AI 모델 성능 개선 및 모바일 환경에 맞춘 경량화 작업.
- 12주차: 모바일 애플리케이션과 백엔드 시스템 간의 통신 안정화. 테스트 환경에서의 통합 테스트 진행.
- 2차 중간평가 목표: Backend와 연동된 전체 서비스 프로토타입 시연.
- 13~14주차: 추가 데이터 수집 및 다양한 모델 아키텍쳐 적용을 통한 성능 향상. 데이터 증강 기법을 적용해 모델의 정확도 및 세부 감정/상황 분류 성능 향상.
- 15주차: 최종 통합 및 사용자 테스트. 실사용자 피드백 반영하여 최종 버전 개선 및 배포 준비.
- 최종평가 목표: 어플리케이션 및 Backend 서버를 배포함.

## 사용할 기술

### ResNet
- 푸리에 변환, 멜 필터뱅크 -> 음성 데이터를 3차원 이미지 데이터 변환

### ViT와 같은 대규모 Computer vision 아키텍쳐
- CNN과 ViT를 이용해 울음 분석하는 모델 개발 예정

## 세부 일정 및 목표 소개

### 1차 중간평가
- 동물의 내는 소리(X)와 그에 대응되는 감정(Y)을 수집하고 모델에 맞게 데이터 전처리<br n>
- 고양이와 강아지 울음소리 구별하기 위한 신경망과, <br n> 각각 동물의 감정을 판별하는 모델을 개발하기 위한 신경망의 기반을 구축예정
- 앱과 백엔드와의 연동 준비

### 2차 중간평가
- 본격적으로 성능 향상을 위해 여러가지 기법을 사용해보거나, <br n> 하이퍼 파라미터 튜닝을 거쳐서 모델의 성능을 70% 이상 끌어 올릴 계획.
- 앱과 백엔드와의 연동 마무리

### 최종평가
- 실사용을 통해서 모델과의 상호작용이 잘 되도록 하는 것이 목표.